#! /bin/env python

from __future__ import division, print_function,unicode_literals
import argparse
import os
import datetime as dt

# Create table for time series, and maybe a header for meta data.
# Could have option to not overwrite .mo file if it already exists.

class MO(object):
	"""
	Specifications and dumper for output .mo file format.
	No need to construct this class.
	If the orders or units of values change they should also be updated in
	Weather.mo.
	"""
	metal = [
		'name', # Identifier for station/file
		'lat', # Latitude (degree)
		'lon', # Longitude (degree)
		'elev', # Elevation (m)
		'tzone', # Time zone wrt to UTC +ve East (hours)
		'tstart', # Time of first point relative to start of year using local time (s)
		]
	metau = [
		'str',
		'deg',
		'deg',
		'm',
		'h',
		's',
		]
	tabl = [
		'time', # Time starting at zero for first point (s)
		'ghi', # Global horizontal irradiance (W/m2)
		'dni', # Direct normal irradiance (W/m2)
		'dry', # Dry-bulb temperature (degC)
		'dew', # Dew point temperature (degC)
		'rhum', # Relative humidity (%)
		'p', # Pressure (mbar)
		'wdir', # Wind direction (deg)
		'wspd', # Wind speed (m/s)
		]
	tabu = [
		's',
		'W/m2',
		'W/m2',
		'degC',
		'degC',
		'%',
		'mbar',
		'deg',
		'm/s',
		]
	@classmethod
	def dump(cls, fn, meta, data):
		nrow = len(data['time'])
		ncol = len(cls.tabl)
		f = open(fn, 'w')
		f.write('#1\n')
		f.write('double weather('+str(nrow)+','+str(ncol)+')\n')
		# Can check labels to make sure it is a compatible version
		f.write('#METALABELS,'+','.join(cls.metal)+'\n')
		f.write('#METAUNITS,'+','.join(cls.metau)+'\n')
		f.write('#TABLELABELS,'+','.join(cls.tabl)+'\n')
		f.write('#TABLEUNITS,'+','.join(cls.tabu)+'\n')
		# Output metadata line
		f.write('#METADATA,'+','.join(meta[k] for k in cls.metal)+'\n')
		# Output table data
		for i in range(nrow):
			f.write(','.join(data[k][i] for k in cls.tabl)+'\n')
		f.close()

class TMY3(object):
	"""
	Secifications and loader for NREL TMY3 files
	No need to construct this class
	"""
	headi = {
		# See 43156.pdf
		'id': 0, # USAF site identifier
		'name': 1, # Station name
		'state': 2, # Station state
		'timezone': 3, # Site time zone (hours from Greenwich)
		'lat': 4, # Site latitude (deicmal degree)
		'lon': 5, # Site latitude (decimal degree)
		'elev': 6, # Site elevation (m)
		}
	labi = {
		# Note that the labels units conflict with the specification in that
		# one says powers are in Wh and the other in W.  Because the time
		# resolution is 1 hour, these are the same, but care should be taken
		# if trying to adapt this format for higher frequency data.
		'Date (MM/DD/YYYY)': 0,
		'Time (HH:MM)': 1, # Local standard time
		'GHI (W/m^2)': 4, # Global horizontal irradiance *1
		'DNI (W/m^2)': 7, # Direct nomal irradiance *1
		'Dry-bulb (C)': 31, # Dry-bulb temperature *2
		'Dew-point (C)': 34, # Dew-point temperature *2
		'RHum (%)': 37, # Relative humidity *2
		'Pressure (mbar)': 40, # Pressure *2
		'Wdir (degrees)': 43, # Wind direction *2, 360=North, 0=calm
		'Wspd (m/s)': 46, # Wind speed *2

		# *1: during last hour ending in this timestamp
		# *2: at time indicated
		}
	sources_to_check = [
		5,
		8,
		9,
		32,
		35,
		38,
		41,
		44,
		47,
		]
	@classmethod
	def load(cls, fn):
		f = open(fn)
		header = f.readline().strip().split(',')
		labels = f.readline().strip().split(',')

		# Check labels are as expected
		for k in cls.labi:
			assert k == labels[cls.labi[k]], 'Label ' + k + ' not matching'

		dat = []
		for line in f.readlines():
			dat.append(line.strip().split(','))
		f.close()
		
		# Check data is expected length
		assert(len(dat) == 8760)
		
		# Check first row to see if data missing.  Austela uses value of -9900,
		# and a ? in the meteorological 'source flags' column is also often used
		# to indicate missing data.
		for c in cls.sources_to_check:
			assert dat[0][c] != '?', 'Value ' + labels[c] + ' might be missing'
		for k in cls.labi:
			assert dat[0][cls.labi[k]] != '-9900', ('Value ' + k +
					' might be missing')

		# Different months can come from different years and the data only
		# covers 365 days.
		# Using first data point to get time from start of year
		date_first = dt.datetime.strptime(dat[0][cls.labi['Date (MM/DD/YYYY)']]
				+ ' ' + dat[0][cls.labi['Time (HH:MM)']], '%m/%d/%Y %H:%M')
		date_year = dt.datetime.strptime(dat[0][cls.labi['Date (MM/DD/YYYY)']],
				'%m/%d/%Y')
		t_start = (date_first - date_year).total_seconds()

		meta = {}
		meta['name'] = (header[cls.headi['id']]
				+ '-' + header[cls.headi['name']])
		meta['lat'] = header[cls.headi['lat']]
		meta['lon'] = header[cls.headi['lon']]
		meta['elev'] = header[cls.headi['elev']]
		meta['tzone'] = header[cls.headi['timezone']]
		meta['tstart'] = str(t_start)

		tab = {k: [] for k in MO.tabl}
		for i, row in enumerate(dat):
			tab['time'].append(str(i*3600))
			tab['ghi'].append(row[cls.labi['GHI (W/m^2)']])
			tab['dni'].append(row[cls.labi['DNI (W/m^2)']])
			tab['dry'].append(row[cls.labi['Dry-bulb (C)']])
			tab['dew'].append(row[cls.labi['Dew-point (C)']])
			tab['rhum'].append(row[cls.labi['RHum (%)']])
			tab['p'].append(row[cls.labi['Pressure (mbar)']])
			tab['wdir'].append(row[cls.labi['Wdir (degrees)']])
			tab['wspd'].append(row[cls.labi['Wspd (m/s)']])

		return (meta, tab)

class EPW(object):
	"""
	Secifications and loader for EnergyPlus EPW files
	No need to construct this class
	"""
	head_names = [
		'LOCATION',
		'DESIGN CONDITIONS',
		'TYPICAL/EXTREME PERIODS',
		'GROUND TEMPERATURES',
		'HOLIDAYS/DAYLIGHT SAVINGS',
		'COMMENTS 1',
		'COMMENTS 2',
		'DATA PERIODS',
		]
	headi = {
		'name': 1, # Station name
		'lat': 6, # Site latitude (deicmal degree)
		'lon': 7, # Site latitude (decimal degree)
		'timezone': 8, # Site time zone (hours from Greenwich)
		'elev': 9, # Site elevation (m)
		}
	labi = {
		'year': 0,
		'month': 1, # 1-12
		'day': 2,
		'hour': 3, # 1-24, where 1 is for region : 00:01 - 01:00
		'minute': 4, # 1-60
		'dry': 6, # (degC) -70-70 Dry bulb temperature
		'dew': 7, # (degC) -70-70 Dew point temperature
		'rhum': 8, # (%) 0-110 Relative humidity
		'p': 9, # (Pa) 31,000-120,000 Pressure
		'ghi': 13, # (Wh/m2) >=0 Global horizontal radiation *1
		'dni': 14, # (Wh/m2) >=0 Direct normal radiation *1
		'wdir': 20, # (deg) 0-360 Wind direction 360=North, 0=calm
		'wspd': 21, # (m/s) 0-40 Wind speed

		# *1: during last hour ending in this timestamp
		# *2: at time indicated
		}
	missv = {
		# Values that are used if data is missing
		'year': None,
		'month': None,
		'day': None,
		'hour': None,
		'minute': None,
		'dry': 99.9,
		'dew': 99.9,
		'rhum': 999,
		'p': 999999,
		'ghi': 9999,
		'dni': 9999,
		'wdir': 999,
		'wspd': 999,
		}
	@classmethod
	def load(cls, fn):
		f = open(fn)
		header = {}
		for n in cls.head_names:
			header[n] = f.readline().strip().split(',')
			assert n == header[n][0]

		

		dat = []
		for line in f.readlines():
			dat.append(line.strip().split(','))
		f.close()
		
		# Only currently know to handle 1 data period (not sure what it means)
		assert int(header['DATA PERIODS'][1]) == 1

		pnts_per_hour = int(header['DATA PERIODS'][2])
		# Check data is expected length
		assert len(dat) == 8760*pnts_per_hour
		
		# Check no missing data
		for d in dat:
			for n in cls.missv:
				if cls.missv[n] is not None:
					assert float(d[cls.labi[n]]) != cls.missv[n], ('Value ' + n +
							' is missing')

		# Using first data point to get time from start of year
		date_first = dt.datetime(
					int(dat[0][cls.labi['year']]),
					int(dat[0][cls.labi['month']]),
					int(dat[0][cls.labi['day']]),
					int(dat[0][cls.labi['hour']])-1 # convert from 1-24 to 0-23
					)
		date_first += dt.timedelta(minutes=int(dat[0][cls.labi['minute']]))
		date_year = dt.datetime(int(dat[0][cls.labi['year']]), 1, 1)

		t_start = (date_first - date_year).total_seconds()

		meta = {}
		meta['name'] = header['LOCATION'][cls.headi['name']]
		meta['lat'] = header['LOCATION'][cls.headi['lat']]
		meta['lon'] = header['LOCATION'][cls.headi['lon']]
		meta['elev'] = header['LOCATION'][cls.headi['elev']]
		meta['tzone'] = header['LOCATION'][cls.headi['timezone']]
		meta['tstart'] = str(t_start)

		tab = {k: [] for k in MO.tabl}
		for i, row in enumerate(dat):
			tab['time'].append(str(i*(3600//pnts_per_hour)))
			tab['ghi'].append(str(float(row[cls.labi['ghi']])/pnts_per_hour)) # convert Wh/m2 to W/m2
			tab['dni'].append(str(float(row[cls.labi['dni']])/pnts_per_hour)) # convert Wh/m2 to W/m2
			tab['dry'].append(row[cls.labi['dry']])
			tab['dew'].append(row[cls.labi['dew']])
			tab['rhum'].append(row[cls.labi['rhum']])
			tab['p'].append(str(float(row[cls.labi['p']])*0.01)) # convert Pa to mbar
			tab['wdir'].append(row[cls.labi['wdir']])
			tab['wspd'].append(row[cls.labi['wspd']])

		return (meta, tab)

def load_file(fn):
	# First identify then pass off to processor
	name, ext = os.path.splitext(fn)
	parser = TMY3
	if ext == '.epw' or ext == '.EPW':
		parser = EPW

	return parser.load(fn)

def save_file(fn, dat):
	MO.dump(fn, dat[0], dat[1])

if __name__ == '__main__':
	parser = argparse.ArgumentParser()
	parser.add_argument('file')
	args = parser.parse_args()

	fn = args.file
	dat = load_file(fn)
	save_file(os.path.splitext(fn)[0] + '.motab', dat)
