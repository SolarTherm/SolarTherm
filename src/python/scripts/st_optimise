#! /bin/env python
from __future__ import division
import argparse
import os
import functools
from solartherm import postproc
from solartherm import simulation

import pylab as pl
import random
import time
#import multiprocessing
import scoop
from scoop import futures

t_start = time.time()

try:
	from scipy import optimize as sciopt
except ImportError:
	sciopt = None
try:
	from pyswarm import pso
except ImportError:
	pso = None
try:
	import cma
except ImportError:
	cma = None
try:
	import pyevolve as pe
	from pyevolve import GSimpleGA, G1DList, Initializators, Crossovers, Selectors, Mutators, Scaling, Consts
except ImportError:
	pe = None

try:
	import deap
	from deap import algorithms, base, creator, tools
except ImportError:
	deap = None

# TODO: add flag for maximisation (e.g., to use capacity factor)
# TODO: add flag for multi-objective optimisation (e.g., to minimse lcoe and maximise capacity factor)

#	cfunc = functools.partial(cost_function, sim, mat_fn,
#			(args.start, args.stop, args.step),
#			args.v, scale, offset, perf_i, par_n)

def cost_function(sim, mat_fn, stime, verb, scale, offset, perf_i, par_n, resultclass, op_meth, par_val):
	par_v = [str(v*scale[i] + offset[i]) for i, v in enumerate(par_val)]
	sim.update_pars(par_n, par_v)
	sim.simulate(start=stime[0], stop=stime[1], step=stime[2])

	res = resultclass(mat_fn)
	cost = res.calc_perf()[perf_i]

	if verb:
		print(par_v)
		print(cost)

	if op_meth == 'ga2':
		return cost,
	else:
		return cost


if __name__ == '__main__':
	"""
	Should make sure parameters are not final (protected), or that other
	derived parameters are final.
	"""
	parser = argparse.ArgumentParser()
	parser.add_argument('file',
			help='model file name')
	parser.add_argument('-v', action='store_true',
			help='verbose')
	parser.add_argument('--nomc', action='store_true',
			help='no model compilation')
	parser.add_argument('--nosc', action='store_true',
			help='no simulation compilation')
	parser.add_argument('--noc', action='store_true',
			help='no compilation at all (--nomc and --nosc)')
	parser.add_argument('--start', type=str, default='0',
			help='simulation start time: <number>[,y,d,m,s]')
	parser.add_argument('--stop', type=str, default='1y',
			help='simulation stop time: <number>[,y,d,m,s]')
	parser.add_argument('--step', type=str, default='5m',
			help='simulation time step: <number>[,y,d,m,s]')
	parser.add_argument('--method', type=str, default='Nelder-Mead',
			help='cma, pso, ga1, ga2 or one of the scipy optimisation methods')
	parser.add_argument('--maxiter', type=int, default=20,
			help='maximum number of iterations (not necessarily number of simulations)')
	parser.add_argument('--cost', type=str, default='lcoe',
			help='quantity to minimise (produced by post processing)')
	parser.add_argument('par', metavar='P', type=str, nargs='*',
			help='parameters with bounds and optional starting value in form PNAME=LOW,HIGH[,START]')
	parser.add_argument('--fuel', action='store_true',
			help='run post-processing calculations for levelised cost of fuel')			
	args = parser.parse_args()
	parser.add_argument('--framework', type=str, default='SOO_min',
			help='SOO_min, SOO_max or MOO, being single objective minimisation, single objective maximisation, or multi-objective optimisation respectively')


	sim = simulation.Simulator(args.file);

	if not args.noc:
		if not args.nomc:
			print('Compiling model')
			sim.compile_model()
		if not args.nosc:
			print('Compiling simulator')
			sim.compile_sim(args=([] if args.v else ['-s']))

	if args.fuel:
		resultclass = postproc.SimResultFuel
	else:
		resultclass = postproc.SimResultElec

	op_meth = args.method

	sim.load_init()

	par_n = [] # names
	par_b = [] # bounds
	par_0 = [] # start
	offset = []
	scale = []
	# Don't need bounds (pass None for variable to minimize)
	for pp in args.par:
		k, v = pp.split('=')
		par_n.append(k)
		vals = [simulation.parse_var_val(vv, sim.get_unit(k))
			for vv in v.split(',')]
		assert len(vals) >= 2, 'Expected parameter bounds + optional start value'
		lb = vals[0]
		ub = vals[1]
		assert lb <= ub, 'Lower bound greater than upper bound'
		#par_b.append([lb, ub])
		p0 = (ub + lb)/2
		if len(vals) == 3:
			p0 = vals[2]
		#par_0.append(p0)
		offset.append(lb)
		scale.append((ub - lb))
		par_b.append([0, 1])
		par_0.append((p0 - lb)/(ub - lb))

	mat_fn = sim.model + '_res.mat'

	try:
		perf_i = resultclass.perf_n.index(args.cost)
	except ValueError:
		raise ValueError('Cost value should be one of '
				+ str(resultclass.perf_n))

	cfunc = functools.partial(cost_function, sim, mat_fn,
			(args.start, args.stop, args.step),
			args.v, scale, offset, perf_i, par_n, resultclass, op_meth)

	print "\n\n\nOptimisation parameter(s): ", par_n, "\n\n\n"

	if args.method == 'pso':
		assert pso is not None, 'Library for pso is not installed'
		swarmsize=5
		lb = [v[0] for v in par_b]
		ub = [v[1] for v in par_b]
		res = pso(cfunc, lb, ub, maxiter=args.maxiter, swarmsize=5)
		cand = [scale[i]*v + offset[i] for i, v in enumerate(res[0])]

		t_end = time.time() # NOTE: the clock does not work on the multicored version!
		t_dur = t_end - t_start # Time elapsed to (succesfully) finish the optimisation

		print "\n\nTotal time elapsed: ", t_dur, "seconds."
		print "Optimal design parameters: ", (cand)
		print "Optimal objective function: ", (res[1])
	elif args.method == 'cma':
		assert cma is not None, 'Library for cma is not installed'
		sigma0 = 0.2 # "step size", should be around 1/4 of search domain
		popsize = 5
		res = cma.fmin(cfunc, par_0, sigma0,
				restarts=0,
				options={
						#'maxfevals': args.maxiter,
						'maxiter': args.maxiter,
						'popsize': popsize,
				})
		cand = [scale[i]*v + offset[i] for i, v in enumerate(res[0])]

		t_end = time.time() # NOTE: the clock does not work on the multicored version!
		t_dur = t_end - t_start # Time elapsed to (succesfully) finish the optimisation

		print "\n\n\Total time elapsed: ", t_dur, "seconds."
		print "Optimal design parameters: ", (cand)
		print "Optimal objective function: ", (res[1])
	elif args.method == 'ga1':
		assert pe is not None, 'Library for pyevolve is not installed'

		lb = [v[0] for v in par_b] # Normalised lower bound
		ub = [v[1] for v in par_b] # Normalised upper bound

		pop_size = 100 # Set number of individuals in population
		ngen = 2 # Total number of generation to run
		cxpb = 0.98 # Crossover probability
		mutpb = 0.01 # Mutation probability
		freq_stats = 10 # Frequency of stats
		paral_eval = False # To enable parallel evaluation. Only use it when the fitness function is slow!

		pl.ion()
		numpoints = len(par_n) # Number of design parameters

		genome = G1DList.G1DList(numpoints) # Genome instance
		genome.setParams(rangemin = lb[0], rangemax = ub[0]) # Set the range min and max of the 1D List
		genome.evaluator.set(cfunc) # The evaluator function (fitness/objective function)	
		genome.initializator.set(Initializators.G1DListInitializatorReal) # Real initialization function of G1DList
		genome.crossover.set(Crossovers.G1DListCrossoverUniform) # The G1DList Uniform Crossover
		genome.mutator.set(Mutators.G1DListMutatorRealRange) # Simple real range mutator for G1DList

		ga = GSimpleGA.GSimpleGA(genome) # Genetic algorithm instance
		ga.selector.set(Selectors.GTournamentSelector) # Set the selector method
		ga.setMinimax(Consts.minimaxType["minimize"])
		#ga.setMinimax(0)
		ga.setPopulationSize(pop_size) # Set the population size for each generation
		ga.setGenerations(ngen) # Set the number of generation
		ga.setCrossoverRate(cxpb) # Set the crossover rate  
		ga.setMutationRate(mutpb) # Set the mutation rate
		ga.terminationCriteria.set(GSimpleGA.ConvergenceCriteria) # Terminate the evolution when the population have converged
		pop = ga.getPopulation() # Return the internal population of GA Engine
		pop.scaleMethod.set(Scaling.SigmaTruncScaling) # Sigma Truncation scaling scheme, allows negative scores
		ga.evolve(freq_stats=freq_stats) # Run the optimisation and print the stats of the ga every n generation
		ga.setMultiProcessing(flag=paral_eval, full_copy=False) # Set the flag to enable/disable the use of python multiprocessing module

		res = ga.bestIndividual() # Best individual in normalised form
		cand = [scale[i]*v + offset[i] for i, v in enumerate(res.genomeList)] # Denormalised best individual
		print "Optimal design parameters: ", (cand)
		print "Optimal objective function: ", (res.score)
	elif args.method == 'ga2':
		assert deap is not None, 'Library for deap is not installed'

		lb = [v[0] for v in par_b] # Normalised lower bound
		ub = [v[1] for v in par_b] # Normalised upper bound

		ind_size = len(par_n) # Number of design parameters
		pop_size = 100 # Set number of individuals in population
		ngen = 2 # Total number of generation to run
		cxpb = 0.98 # Crossover probability
		cxpb_in = 0.5 # Probability of crossover within individual
		mutpb = 0.02 # Mutation probability
		mutpb_in = 0.01 # Probability of mutation within individual
		paral_eval = False # To enable parallel evaluation. Only use it when the fitness function is slow!
		n_cores = 4 # Number of cores for parallel evaluation of the fitness function

		creator.create("FitnessMin", base.Fitness, weights=(-1.0,)) 
		creator.create("Individual", list, fitness=creator.FitnessMin)

		toolbox = base.Toolbox() # Attribute generator
		toolbox.register("attr_float", random.uniform, lb[0], ub[0]) # Generate a vector of uniform random numbers within the lower and upper bounds of the design variables
		toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_float, ind_size) # Structure initializer for individuals
		toolbox.register("population", tools.initRepeat, list, toolbox.individual) # Structure initializer for the population

		# Decorator to obtain a constrained domain that is applied to the mutation and crossover
		#def checkBounds(min, max):
			#def decorator(func):
				#def wrappper(*args, **kargs):
					#offspring = func(*args, **kargs)
					#for child in offspring:
						#for i in range(len(child)):
							#if child[i] > max:
								#child[i] = max
							#elif child[i] < min:
								#child[i] = min
					#return offspring
				#return wrappper
			#return decorator

		# NOTE: For penalty function-based constraint handling see: http://deap.readthedocs.io/en/master/tutorials/advanced/constraints.html

		# Register the GA operators
		toolbox.register("evaluate", cfunc) # Set the evaluation function
		toolbox.register("mate", tools.cxUniform, indpb=cxpb_in) # Set the crossover type
		toolbox.register("mutate", tools.mutFlipBit, indpb=mutpb_in) # Set the mutation type
		#toolbox.register("select", tools.selNSGA2) # Set the selector method
		toolbox.register("select", tools.selTournament, tournsize=3) # Set the selector method

		#toolbox.decorate("mate", checkBounds(lb[0], ub[0])) # Check bounds for a constrained domain
		#toolbox.decorate("mutate", checkBounds(lb[0], ub[0])) # Check bounds for a constrained domain

		# Parallel evaluation by running the computation multicore
		if paral_eval:
			#pool = multiprocessing.Pool(processes=n_cores)
			#toolbox.register("map", pool.map) # Change the map functions everywhere to toolbox.map to make the algorithm use a multicored map
			toolbox.register("map", futures.map) # Change the map functions everywhere to toolbox.map to make the algorithm use a multicored map

		pop = toolbox.population(n=pop_size) # Set the size of population (individuals)

		fitnesses = list(toolbox.map(toolbox.evaluate, pop)) # Evaluate the entire population

		for ind, fit in zip(pop, fitnesses):
			ind.fitness.values = fit  # Run the fitness (min mean on each of the individuals)

		fits = [ind.fitness.values[0] for ind in pop] # # Gather all the fitnesses in one list

		# Begin the evolution
		for g in range(ngen):
			print("-- Generation %i --" % g)

			# Select the next generation individuals
			offspring = toolbox.select(pop, len(pop)) # Select the best individuals in the population

			# Clone the selected individuals
			offspring = list(toolbox.map(toolbox.clone, offspring)) #Create the offspring

			# Apply crossover on the offspring
			for child1, child2 in zip(offspring[::2], offspring[1::2]):
				if random.random() < cxpb:
					toolbox.mate(child1, child2)
					del child1.fitness.values
					del child2.fitness.values

			# Apply mutation on the offspring
			for mutant in offspring:
				# mutate an individual with probability mutpb
				if random.random() < mutpb:
					toolbox.mutate(mutant)
					del mutant.fitness.values

			# Evaluate the individuals with an invalid fitness
			invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
			fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)
			for ind, fit in zip(invalid_ind, fitnesses):
				ind.fitness.values = fit

			# Replace the enitre population with the offspring
			pop[:] = offspring
			fits = [ind.fitness.values[0] for ind in pop]

			print(tools.selBest(pop, 1)[0]) # Best individual in the current generation
			print(tools.selBest(pop, 1)[0].fitness.values[0]) # Best fitness in the current generation

		# For parallel evaluation using multiprocessing
		#if paral_eval:
			#pool.close()
			#pool.join()

		res = tools.selBest(pop, 1)[0] # Best individual in normalised form
		cand = [scale[i]*v + offset[i] for i, v in enumerate(res)] # Denormalised best individual

		t_end = time.time() # NOTE: the clock does not work on the multicored version!
		t_dur = t_end - t_start # Time elapsed to (succesfully) finish the optimisation

		print "\n\nTotal time elapsed: ", t_dur, "seconds."
		print "Optimal design parameters: ", (cand)
		print "Optimal objective function: ", (res.fitness.values[0])
	else:
		res = sciopt.minimize(cfunc, par_0, method=args.method, bounds=par_b,
				options={
					#'maxfev': args.maxiter,
					'maxiter': args.maxiter,
					'disp': True,
				})
		print(res)
		cand = [scale[i]*v + offset[i] for i, v in enumerate(res.x)]

		t_end = time.time() # NOTE: the clock does not work on the multicored version!
		t_dur = t_end - t_start # Time elapsed to (succesfully) finish the optimisation

		print "\n\nTotal time elapsed: ", t_dur, "seconds."
		print "Optimal design parameters: ", (cand)
		print "Optimal objective function: ", (res.fun)
