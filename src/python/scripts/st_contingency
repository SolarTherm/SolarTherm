#! /bin/env python

from solartherm.contingency import Contingency
from solartherm.dakota import DakotaSampleIn
from solartherm import simulation
from solartherm import params
import multiprocessing as mp
import numpy as np
import time
import os
import argparse
import itertools
import subprocess

if __name__=='__main__':
	parser = argparse.ArgumentParser()	

	parser.add_argument('file',
			help='model file name')	
	parser.add_argument('-v', action='store_true',
			help='verbose')
	parser.add_argument('--start', type=str, default='0',
			help='simulation start time: <number>[,y,d,m,s]')
	parser.add_argument('--stop', type=str, default='1y',
			help='simulation stop time: <number>[,y,d,m,s]')
	parser.add_argument('--step', type=str, default='5m',
			help='simulation time step: <number>[,y,d,m,s]')
	parser.add_argument('--tolerance', type=str, default='1e-04',
			help='simulation tolerance: <number>')
	parser.add_argument('--initStep', type=str, default=None,
			help='simulation initial step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--maxStep', type=str, default=None,
			help='simulation maximum absolute step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--integOrder', type=str, default='5',
			help='simulation maximum integration order used by dassl and ida methods: <number>')
	parser.add_argument('--solver', type=str, default='dassl',
			help='solver choice for OpenModelica')
	parser.add_argument('--nls', type=str, default='homotopy',
			help='non-linear solver choice for OpenModelica e.g. newton, hybrid, kinsol, mixed, and homotopy')
	parser.add_argument('--lv', type=str, default='-LOG_SUCCESS,-stdout',
			help='a comma-separated String list specifing which logging levels to enable, e.g. LOG_DASSL,LOG_SOLVER etc')
	parser.add_argument('--fuel', action='store_true',
			help='run post-processing calculations for levelised cost of fuel')	
	parser.add_argument('--np', type=int, default=mp.cpu_count(),
			help='number of processes (set to 0 or 1 for serial mode)')	
	parser.add_argument('--peaker', action='store_true',
			help='peaker configuration')
	parser.add_argument('--runsolstice', action='store_true',
			help='run solstice mcrt')	
	parser.add_argument('--wd', type=str, default='.',
			help='the working directory')	
	parser.add_argument('--restart', action='store_true',
			help='restart by continuing the last simulation (available now only via dakota), the restart file (dakota.rst) must be in the working directory')
	parser.add_argument('--plot', action='store_true',
			help='plot the results')										
	parser.add_argument('--excel', type=str, default=None,
			help='the directry of the input excel data sheet')			
	parser.add_argument('--sample', type=str, default='moga-hybrid',
			help='sampling method, e.g. lhs or moga')			
	parser.add_argument('--ns', type=int, default=10,
			help='number of samples')
	parser.add_argument('--samplefile', type=str, default=None,
			help='directory of a csv file that has the summary of sample data for processing contingency analysis')			


	args = parser.parse_args()
	
	if not os.path.exists(args.wd):
		os.makedirs(args.wd)	
	if not os.path.isabs(args.wd):
		casedir=os.path.join(os.getcwd(),args.wd)
	else:
		casedir=args.wd

	if args.excel ==None:
		raise Exception("\n\nNo excel spreasheet found\nAn excel spreadsheet must be given as the input\n\n")	
	else:
		excel_file=os.path.abspath(args.excel)

	if args.fuel:
		analysis_type='FUEL' # LCOF # TODO hasn't been developed yet
		raise Exception("\nFUEL system has not been developed/tested in the contingency analysis yet\n") 
	else:
		analysis_type='CONTINGENCY' # LCOE, electricity
				
		
	fn=os.path.abspath(args.file)	
	mn=os.path.splitext(os.path.split(fn)[1])[0] # model name
	
	os.chdir(casedir)		
	sim = simulation.Simulator(fn=fn, fusemount=False)
	# compile the model		
	sim.compile_model()
	sim.compile_sim(args=['-s'])
					
	# load parameters from the spreadsheet	
	input_xml=mn+'_init.xml'
	tree=params.Tree()
	tree.load_xml(input_xml)
	params.load_values_from_excel(excel_file, tree)
	tree.write_xml(input_xml)
	par_n=tree.filter_type(1) # 1 is for uncertainty analysis
	par_n_perf=tree.filter_category('p') # 'p' are the performance uncertainty parameters
	par_n_cost=tree.filter_category('c') # 'c' are the cost uncertainty parameters		
	par_n_des=tree.filter_type(2) # 2 are the design parameters				

	method_args={}	
	if args.sample=='moga-hybrid':
		method='moga'
		method_args['max_eval']=args.ns
		method_args['pop_size']=args.np			
		stdevs=None
		dists=None
		
	else:
		method='uq'
		method_args['sample_type']='lhs'
		method_args['num_sample']=args.ns
		stdevs=None
		dists=['uniform']

	var_names=par_n_des
	nominals=[]
	lbs=[]
	ubs=[]
	signs=[1]
	for n in par_n_des:
		nominals.append(tree.get(n+'.nominal'))	
		lbs.append(tree.get(n+'.boundary1'))
		ubs.append(tree.get(n+'.boundary2'))
	for n in par_n_perf:	
		lbs.append(tree.get(n+'.boundary1'))
		ubs.append(tree.get(n+'.boundary2'))	
		signs.append(tree.get(n+'.sign'))						
	res_names=['lcoe']+par_n_perf


	if args.samplefile==None:
		# call dakota to sample the data
		if args.restart:	
			print('Continue generating data sample by restart (dakota.rst)')
			if args.np>1:
				subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst'%args.np, shell=True)
			else:			
				subprocess.call('dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst', shell=True)
		
		else:
			print('Generating data sample by Dakota')		
			dkt=DakotaSampleIn(casedir=casedir, fn=fn, analysis_type=analysis_type, method=method, args=method_args, var_names=var_names, nominals=nominals, lbs=lbs, ubs=ubs, stdevs=stdevs, dists=dists, start=args.start, stop=args.stop, step=args.step, initStep=args.initStep, maxStep=args.maxStep, integOrder=args.integOrder, tolerance=args.tolerance, solver=args.solver, nls=args.nls, lv=args.lv, runsolstice=int(args.runsolstice), peaker=int(args.peaker), res_names=res_names, signs=signs)

			subprocess.call('chmod a+x %s/interface_bb.py'%casedir, shell=True)
	
			if args.np>1:
				subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout'%args.np, shell=True)
			else:
				subprocess.call('dakota -i sample.in -o sample.out > sample.stdout', shell=True)
		print('	%s sample generated'%args.ns)	


		summary=np.array([])
		for i in range(1, args.ns+1):
			fn=casedir+'/summary_report_%.0f.csv'%(i)
			data=np.loadtxt(fn, dtype=str, delimiter=',')
			if i==1:
				summary=np.append(summary, (data[:,0],data[:,1]))
			else:
				summary=np.append(summary, data[:,1])

		summary=summary.reshape(int(args.ns+1), int(len(summary)/(args.ns+1)))
		summaryfile=casedir+'/summary_all.csv'
		np.savetxt(summaryfile, summary, fmt='%s', delimiter=',')
		

	else:
		print('Load data sample from file: %s'%args.samplefile)			
		summaryfile=args.samplefile

	
	# postprocessing contingency
	# TODO now works up to 2D, need to develop to higher dimensions
	# TODO in the current examples, no cost parameters are involved
	# TO BE ADDED	
	print('Postprocessing contingency')				
	ct=Contingency(casedir=casedir, var_n_des=par_n_des, var_n_perf=par_n_perf, var_n_cost=par_n_cost, summaryfile=summaryfile)
	if args.sample=='moga-hybrid':
		indices, tri_idx, f_lcoe=ct.front_tri()
	elif args.sample=='lhs':				
		indices, f_lcoe=ct.get_front(plot=args.plot)
		tri_idx=None
		
	# new sample of uncertain parameters
	num_ns=1000 # number of new samples
	num_perf=len(par_n_perf)
	num_des=len(par_n_des)				
	new_sample=np.array([])
	for n in par_n_perf:	
		lb=tree.get(n+'.boundary1')
		ub=tree.get(n+'.boundary2')
		v=np.random.uniform(low=lb*1.01, high=ub*0.99, size=num_ns)
		new_sample=np.append(new_sample, v)	
		
	new_sample=new_sample.reshape(num_perf, num_ns)
	new_sample=new_sample.T			
	ns_lcoe, ns_des=ct.get_assessment(indices, f_lcoe, new_sample, tri_idx=tri_idx, plot=args.plot)
	
	title=np.array([])
	data=np.array([])
	for i in range(num_perf):
		title=np.append(title, par_n_perf[i])
		data=np.append(data, new_sample[:,i])
	for n in par_n_des:
		title=np.append(title, n)
		data=np.append(data, ns_des[n])
	title=np.append(title, 'sample lcoe')
	data=np.append(data, ns_lcoe)
	
	data=data.reshape(num_perf+num_des+1, num_ns)
	res=np.hstack((title.reshape(num_perf+num_des+1,1), data))
	np.savetxt(casedir+'/res_contingency.csv', res.T, fmt='%s', delimiter=',')	
	print('Results saved in the case directory:\n	%s'%casedir)		

	ct.get_lcoe_contingency(fn='../Reference_2_res_0.mat', target_lcoe=None, likelihood=0.7)
	ct.plot_cdfs()
	ct.plot_sensitivity()
	
	
	
	
