#! /bin/env python

from solartherm.contingency import Contingency
from solartherm.dakota import DakotaSampleIn
from solartherm import simulation
from solartherm import params
import multiprocessing as mp
import numpy as np
import time
import os
import argparse
import itertools
import subprocess

if __name__=='__main__':
	parser = argparse.ArgumentParser()	

	parser.add_argument('file',
			help='model file name')	
	parser.add_argument('-v', action='store_true',
			help='verbose')
	parser.add_argument('--start', type=str, default='0',
			help='simulation start time: <number>[,y,d,m,s]')
	parser.add_argument('--stop', type=str, default='1y',
			help='simulation stop time: <number>[,y,d,m,s]')
	parser.add_argument('--step', type=str, default='5m',
			help='simulation time step: <number>[,y,d,m,s]')
	parser.add_argument('--tolerance', type=str, default='1e-04',
			help='simulation tolerance: <number>')
	parser.add_argument('--initStep', type=str, default=None,
			help='simulation initial step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--maxStep', type=str, default=None,
			help='simulation maximum absolute step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--integOrder', type=str, default='5',
			help='simulation maximum integration order used by dassl and ida methods: <number>')
	parser.add_argument('--solver', type=str, default='dassl',
			help='solver choice for OpenModelica')
	parser.add_argument('--nls', type=str, default='homotopy',
			help='non-linear solver choice for OpenModelica e.g. newton, hybrid, kinsol, mixed, and homotopy')
	parser.add_argument('--lv', type=str, default='-LOG_SUCCESS,-stdout',
			help='a comma-separated String list specifing which logging levels to enable, e.g. LOG_DASSL,LOG_SOLVER etc')
	parser.add_argument('--fuel', action='store_true',
			help='run post-processing calculations for levelised cost of fuel')	
	parser.add_argument('--np', type=int, default=mp.cpu_count(),
			help='number of processes (set to 0 or 1 for serial mode)')	
	parser.add_argument('--peaker', action='store_true',
			help='peaker configuration')
	parser.add_argument('--runsolstice', action='store_true',
			help='run solstice mcrt')	
	parser.add_argument('--wd', type=str, default='.',
			help='the working directory')	
	parser.add_argument('--restart', action='store_true',
			help='restart by continuing the last simulation (available now only via dakota), the restart file (dakota.rst) must be in the working directory')							
	parser.add_argument('--excel', type=str, default=None,
			help='the directry of the input excel data sheet')			
	parser.add_argument('--sample', type=str, default='moga-hybrid',
			help='sampling method, e.g. lhs or moga')			
	parser.add_argument('--ns', type=int, default=10,
			help='number of samples')


	args = parser.parse_args()
	fn=os.path.abspath(args.file)	
	if args.excel ==None:
		raise Exception("\n\nNo excel spreasheet found\nAn excel spreadsheet must be given as the input\n\n")	
	else:
		excel_file=os.path.abspath(args.excel)
	
	if not os.path.exists(args.wd):
		os.makedirs(args.wd)	
	if not os.path.isabs(args.wd):
		casedir=os.path.join(os.getcwd(),args.wd)
	else:
		casedir=args.wd
	os.chdir(casedir)
	
	
	if args.restart:
	
		if args.np>1:
			subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst'%args.np, shell=True)
		else:
			subprocess.call('dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst', shell=True)

	
	else:	

		mn=os.path.splitext(os.path.split(fn)[1])[0] # model name
		sim = simulation.Simulator(fn=fn, fusemount=False)
		# compile the model		
		sim.compile_model()
		sim.compile_sim(args=['-s'])
		
		
		if args.fuel:
			analysis_type='FUEL' # LCOF
		else:
			analysis_type='CONTINGENCY' # LCOE, electricity

					
		# load parameters from the spreadsheet	
		input_xml=mn+'_init.xml'
		tree=params.Tree()
		tree.load_xml(input_xml)
		params.load_values_from_excel(excel_file, tree)
		tree.write_xml(input_xml)
		par_n=tree.filter_type(1) # 1 is for uncertainty analysis
		par_n_perf=tree.filter_category('p') # 'p' are the performance uncertainty parameters
		par_n_cost=tree.filter_category('c') # 'c' are the cost uncertainty parameters		
		par_n_des=tree.filter_type(2) # 2 are the design parameters				


		method_args={}	
		if args.sample=='moga-hybrid':
			method='moga'
			method_args['max_eval']=args.ns
			method_args['pop_size']=args.np			
			var_names=par_n_des
			nominals=[]
			lbs=[]
			ubs=[]
			signs=[1]
			for n in par_n_des:
				nominals.append(tree.get(n+'.nominal'))	
				lbs.append(tree.get(n+'.boundary1'))
				ubs.append(tree.get(n+'.boundary2'))
			for n in par_n_perf:	
				lbs.append(tree.get(n+'.boundary1'))
				ubs.append(tree.get(n+'.boundary2'))	
				signs.append(tree.get(n+'.sign'))						
			res_names=['lcoe']+par_n_perf
			stdevs=None
			dists=None
			
		else:
			method='uq'
			method_args['sample_type']='lhs'
			method_args['num_sample']=args.ns
			var_names=par_n
			par_uniform=tree.filter_dist('uniform',var_names)
			par_pert=tree.filter_dist('pert', var_names)			
			par_normal=tree.filter_dist('normal', var_names)

			dists=[]			
			if len(par_uniform)>0:
				dists.append('uniform')
				lb_uniform=[]
				ub_uniform=[]
				for n in par_uniform:
					b1=tree.get(n+'.boundary1')
					b2=tree.get(n+'.boundary2')
					lb_uniform.append(b1)
					ub_uniform.append(b2)
			if len(par_pert)>0:
				dists.append('pert')
				lb_pert=[]
				ub_pert=[]
				nominal_pert=[]
				for n in par_pert:
					nominal=tree.get(n+'.nominal')					
					b1=tree.get(n+'.boundary1')
					b2=tree.get(n+'.boundary2')
					nominal_pert.append(nominal)
					lb_pert.append(b1)
					ub_pert.append(b2)				
			if len(par_normal)>0:
				dists.append('normal')
				mean=[]
				stdev=[]
				for n in par_normal:
					m=tree.get(n+'.nominal')
					sd=tree.get(n+'.boundary1')
					mean.append(m)
					stdev.append(sd)
			
			if len(dists)==1:
				if 'uniform' in dists:
					var_names=par_uniform
					lbs=lb_uniform
					ubs=ub_uniform
					nominals=None
					stdevs=None					
				elif 'pert' in dists:
					var_name=par_pert
					nominals=nominal_pert
					lbs=lb_pert
					ubs=ub_pert
					stdevs=None
				elif 'normal' in dists:
					var_name=par_normal
					nominals=mean
					stdevs=stdev
					lbs=None
					ubs=None
					
			elif len(dists)==2:
				if 'normal' not in dists:
					# uniform and pert distributions
					var_names=[par_uniform, par_pert]
					lbs=[lb_uniform, lb_pert]
					ubs=[ub_uniform, ub_pert]
					nominals=[[], nominal_pert]
					stdevs=None
				elif 'pert' not in dists:
					# uniform and normal distributions
					var_names=[par_uniform, par_normal]
					lbs=[lb_uniform]
					ubs=[ub_uniform]
					nominals=None
					stdevs=stdev			
				elif 'uniform' not in dists:
					# pert and normal distributions
					var_names=[par_pert, par_normal]
					lbs=[lb_pert]
					ubs=[ub_pert]
					nominals=[nominal_pert, mean]
					stdevs=stdev					
								
			elif len(dists)==3:
					var_names=[par_pert, par_normal]
					lbs=[lb_uniform, lb_pert]
					ubs=[ub_uniform, ub_pert]
					nominals=[[], nominal_pert, mean]
					stdevs=stdev					
			res_names=['lcoe']
			signs=[1]

	
		dkt=DakotaSampleIn(casedir=casedir, fn=fn, analysis_type=analysis_type, method=method, args=method_args, var_names=var_names, nominals=nominals, lbs=lbs, ubs=ubs, stdevs=stdevs, dists=dists, start=args.start, stop=args.stop, step=args.step, initStep=args.initStep, maxStep=args.maxStep, integOrder=args.integOrder, tolerance=args.tolerance, solver=args.solver, nls=args.nls, lv=args.lv, runsolstice=int(args.runsolstice), peaker=int(args.peaker), res_names=res_names, signs=signs)


		subprocess.call('chmod a+x %s/interface_bb.py'%casedir, shell=True)

		if args.np>1:
			subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout'%args.np, shell=True)
		else:
			subprocess.call('dakota -i sample.in -o sample.out > sample.stdout', shell=True)
		
		#TODO postprocessing contingency
