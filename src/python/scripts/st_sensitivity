#! /bin/env python

from solartherm.dakota import DakotaSampleIn
from solartherm import simulation
from solartherm import params
import multiprocessing as mp
import numpy as np
import time
import os
import argparse
import itertools
import subprocess

if __name__=='__main__':
	parser = argparse.ArgumentParser()	

	parser.add_argument('file',
			help='model file name')	
	parser.add_argument('-v', action='store_true',
			help='verbose')
	parser.add_argument('--start', type=str, default='0',
			help='simulation start time: <number>[,y,d,m,s]')
	parser.add_argument('--stop', type=str, default='1y',
			help='simulation stop time: <number>[,y,d,m,s]')
	parser.add_argument('--step', type=str, default='5m',
			help='simulation time step: <number>[,y,d,m,s]')
	parser.add_argument('--tolerance', type=str, default='1e-04',
			help='simulation tolerance: <number>')
	parser.add_argument('--initStep', type=str, default=None,
			help='simulation initial step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--maxStep', type=str, default=None,
			help='simulation maximum absolute step size used by dassl and ida methods: <number>[,y,d,m,s]')
	parser.add_argument('--integOrder', type=str, default='5',
			help='simulation maximum integration order used by dassl and ida methods: <number>')
	parser.add_argument('--solver', type=str, default='dassl',
			help='solver choice for OpenModelica')
	parser.add_argument('--nls', type=str, default='homotopy',
			help='non-linear solver choice for OpenModelica e.g. newton, hybrid, kinsol, mixed, and homotopy')
	parser.add_argument('--lv', type=str, default='-LOG_SUCCESS,-stdout',
			help='a comma-separated String list specifing which logging levels to enable, e.g. LOG_DASSL,LOG_SOLVER etc')
	parser.add_argument('--fuel', action='store_true',
			help='run post-processing calculations for levelised cost of fuel')	
	parser.add_argument('--h2', action='store_true',
			help='run post-processing calculations for levelised cost of h2')
	parser.add_argument('--np', type=int, default=mp.cpu_count(),
			help='number of processes (set to 0 or 1 for serial mode)')	
	parser.add_argument('--excel', type=str, default=None,
			help='the directry of the input excel data sheet')
	parser.add_argument('--peaker', action='store_true',
			help='peaker configuration')
	parser.add_argument('--runsolstice', action='store_true',
			help='run solstice mcrt')
	parser.add_argument('--mode', type=str, default='uncertainty',
			help='type of study: uncertainty, parametric or optimisation')
	parser.add_argument('--sample', type=str, default='lhs',
			help='sampling method, e.g. lhs or random')
	parser.add_argument('--ns', type=int, default=10,
			help='number of samples')
	parser.add_argument('--dist', type=str, default='uniform',
			help='distribution of variables, e.g. uniform, normal, pert etc')
	parser.add_argument('par', metavar='P', type=str, nargs='*',
			help='parameters with bounds and optional starting value in form PNAME=LOW,HIGH[,START]')
	parser.add_argument('--wd', type=str, default='.',
			help='the working directory')
	parser.add_argument('--restart', type=str, default=None,
			help='restart by continuing the last simulation (available now only via dakota), given the directory where dakota.rst is located')

	args = parser.parse_args()

	fn=os.path.abspath(args.file)
	mn=os.path.splitext(os.path.split(fn)[1])[0] # model name

	if args.fuel:
		system='FUEL'
	elif args.h2:
		system='H2'
	else:
		system='ELECTRICITY'

	if not os.path.exists(args.wd):
		os.makedirs(args.wd)	
	if not os.path.isabs(args.wd):
		savedir=os.path.join(os.getcwd(),args.wd)
	else:
		savedir=args.wd

	os.chdir(args.wd)
	
	# compile the model first
	sim = simulation.Simulator(fn=fn, fusemount=False)
	sim.compile_model()
	sim.compile_sim(args=['-s'])
	
	dists=[]
	if args.excel!=None:
		#if not os.path.exists(mn):
		#	sim = simulation.Simulator(fn=fn, fusemount=False)
		#	sim.compile_model()
		#	sim.compile_sim(args=['-s'])
		input_xml=mn+'_init.xml'
		tree=params.Tree()
		tree.load_xml(input_xml)
		params.load_values_from_excel(args.excel, tree)
		tree.write_xml(input_xml)

		par_n=tree.filter_type(1) # 1 is for uncertainty analysis
		par_uniform=tree.filter_dist('uniform',par_n)
		par_normal=tree.filter_dist('normal', par_n)
		par_pert=tree.filter_dist('pert', par_n)

		#uniform
		if len(par_uniform)>0:
			dists.append('uniform')
			lb_uniform=[]
			ub_uniform=[]
			for n in par_uniform:
				b1=tree.get(n+'.boundary1')
				b2=tree.get(n+'.boundary2')
				lb_uniform.append(b1)
				ub_uniform.append(b2)

		# normal
		if len(par_normal)>0:
			dists.append('normal')		
			mean=[]
			stdev=[]
			for n in par_normal:
				m=tree.get(n+'.nominal')
				sd=tree.get(n+'.boundary1')
				mean.append(m)
				stdev.append(sd)
		# pert
		if len(par_pert)>0:
			dists.append('pert')			
			nominal_pert=[]
			lb_pert=[]
			ub_pert=[]
			for n in par_pert:
				nominal=tree.get(n+'.nominal')	
				b1=tree.get(n+'.boundary1')
				b2=tree.get(n+'.boundary2')	
				nominal_pert.append(nominal)
				lb_pert.append(b1)
				ub_pert.append(b2)

	else:
		# if the parameters are passed from the command line directly
		# (not from the spreadsheet)
		# all the parameters are in the same distribution

		dist_type=args.dist
		dists.append(dist_type)		

		if dist_type=='uniform':
			lb_uniform=[]
			ub_uniform=[]
			par_uniform=[]
			for pp in args.par:			
				k, v = pp.split('=')
				vals = [(vv) for vv in v.split(',')]			
				lb=vals[0]
				ub=vals[1]			
				par_uniform.append(k)
				lb_uniform.append(b1)
				ub_uniform.append(b2)	
		elif dist_type=='normal':
			mean=[]
			stdev=[]
			par_normal=[]
			for pp in args.par:			
				k, v = pp.split('=')
				vals = [(vv) for vv in v.split(',')]			
				m=vals[0]
				sd=vals[1]		
				par_normal.append(k)
				mean.append(m)
				stdev.append(sd)
		elif dist_type=='pert':
			nominal_pert=[]
			lb_pert=[]
			ub_pert=[]
			par_pert=[]
			for pp in args.par:			
				k, v = pp.split('=')
				vals = [(vv) for vv in v.split(',')]						
				nominal=float(vals[0])
				b1=float(vals[1])
				b2=float(vals[2])	
				nominal_pert.append(nominal)
				lb_pert.append(b1)
				ub_pert.append(b2)
				par_pert.append(k)

	if len(dists)==1:
		if 'uniform' in dists:
			var_names=par_uniform
			lbs=lb_uniform
			ubs=ub_uniform
			nominals=None
			stdevs=None					
		elif 'pert' in dists:
			# FIXME an issue has been found
			# in dakota to sample a pert distribution
			# need investigation
			var_name=par_pert
			nominals=nominal_pert
			lbs=lb_pert
			ubs=ub_pert
			stdevs=None
		elif 'normal' in dists:
			var_name=par_normal
			nominals=mean
			stdevs=stdev
			lbs=None
			ubs=None
			
	elif len(dists)==2:
		if 'normal' not in dists:
			# uniform and pert distributions
			var_names=[par_uniform, par_pert]
			lbs=[lb_uniform, lb_pert]
			ubs=[ub_uniform, ub_pert]
			nominals=[[], nominal_pert]
			stdevs=None
		elif 'pert' not in dists:
			# uniform and normal distributions
			var_names=[par_uniform, par_normal]
			lbs=[lb_uniform]
			ubs=[ub_uniform]
			nominals=[[],mean]
			stdevs=stdev			
		elif 'uniform' not in dists:
			# pert and normal distributions
			var_names=[par_normal, par_pert]
			lbs=[[],lb_pert]
			ubs=[[],ub_pert]
			nominals=[mean, nominal_pert]
			stdevs=stdev					
						
	elif len(dists)==3:
			var_names=[par_uniform, par_normal, par_pert]
			lbs=[lb_uniform, [], lb_pert]
			ubs=[ub_uniform, [], ub_pert]
			nominals=[[], mean, nominal_pert]
			stdevs=stdev			

	method_args={'sample_type':'lhs', 'num_sample': args.ns}

	dkt=DakotaSampleIn(casedir=savedir, fn=fn, analysis_type=system, method='uq', args=method_args, var_names=var_names, nominals=nominals, lbs=lbs, ubs=ubs, stdevs=stdevs, dists=dists, start=args.start, stop=args.stop, step=args.step, initStep=args.initStep, maxStep=args.maxStep, integOrder=args.integOrder, tolerance=args.tolerance, solver=args.solver, nls=args.nls, lv=args.lv, runsolstice=int(args.runsolstice), peaker=int(args.peaker), res_names= ['lco_h2','capf'] if args.h2 else ['lcoe'], signs=[1,1] if args.h2 else [1])

	subprocess.call('chmod a+x %s/interface_bb.py'%savedir, shell=True)

	if args.restart!=None:
		os.chdir(args.restart)
		if args.np!=0:

			subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst'%args.np, shell=True)
		else:
			subprocess.call('dakota -i sample.in -o sample.out > sample.stdout -read_restart dakota.rst', shell=True)


	else:
		if args.np!=0:

			subprocess.call('mpirun --use-hwthread-cpus -np %s dakota -i sample.in -o sample.out > sample.stdout'%args.np, shell=True)
		else:
			subprocess.call('dakota -i sample.in -o sample.out > sample.stdout', shell=True)

